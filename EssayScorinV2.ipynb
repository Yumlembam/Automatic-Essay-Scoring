{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EssayScorinV2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yumlembam/Automatic-Essay-Scoring/blob/master/EssayScorinV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "S3DCpIsglmQ1",
        "colab_type": "code",
        "outputId": "f6fd42e7-5bfa-4a09-a2ed-45b8642292a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CGbHB82hoanT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ln -s \"/gdrive/My Drive/Deep learning/Essay_Scoring_V2\" \"/content\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RmGKDb63o8W9",
        "colab_type": "code",
        "outputId": "2bfa3c12-a96f-48d5-a878-4b3eddad012f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "# upload the credential of kaggle account\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e8b5a67-c7f0-4547-b079-35acc1e7f24e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8e8b5a67-c7f0-4547-b079-35acc1e7f24e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"yumlembam\",\"key\":\"dedaadf824834791cc388f3fe11a7370\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "jtIfhmDipJ6c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#before importing the dataset we want to use this code\n",
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "owCluw_ypOo4",
        "colab_type": "code",
        "outputId": "d702b112-4c89-417e-bfd1-7139712b81f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c asap-aes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading training_set_rel3.tsv to /content\n",
            " 58% 9.00M/15.6M [00:01<00:00, 11.5MB/s]\n",
            "100% 15.6M/15.6M [00:01<00:00, 14.0MB/s]\n",
            "Downloading training_set_rel3.xls to /content\n",
            " 58% 11.0M/19.0M [00:00<00:00, 42.8MB/s]\n",
            "100% 19.0M/19.0M [00:00<00:00, 63.3MB/s]\n",
            "Downloading training_set_rel3.xlsx to /content\n",
            " 78% 5.00M/6.39M [00:00<00:00, 29.6MB/s]\n",
            "100% 6.39M/6.39M [00:00<00:00, 30.7MB/s]\n",
            "Downloading valid_set.tsv to /content\n",
            "  0% 0.00/5.05M [00:00<?, ?B/s]\n",
            "100% 5.05M/5.05M [00:00<00:00, 46.3MB/s]\n",
            "Downloading valid_set.xls to /content\n",
            " 82% 5.00M/6.12M [00:00<00:00, 34.0MB/s]\n",
            "100% 6.12M/6.12M [00:00<00:00, 39.0MB/s]\n",
            "Downloading valid_set.xlsx to /content\n",
            "  0% 0.00/2.06M [00:00<?, ?B/s]\n",
            "100% 2.06M/2.06M [00:00<00:00, 140MB/s]\n",
            "Downloading valid_sample_submission_1_column.csv to /content\n",
            "  0% 0.00/14.9k [00:00<?, ?B/s]\n",
            "100% 14.9k/14.9k [00:00<00:00, 18.0MB/s]\n",
            "Downloading valid_sample_submission_1_column_no_header.csv to /content\n",
            "  0% 0.00/14.9k [00:00<?, ?B/s]\n",
            "100% 14.9k/14.9k [00:00<00:00, 15.2MB/s]\n",
            "Downloading valid_sample_submission_2_column.csv to /content\n",
            "  0% 0.00/41.4k [00:00<?, ?B/s]\n",
            "100% 41.4k/41.4k [00:00<00:00, 42.9MB/s]\n",
            "Downloading valid_sample_submission_5_column.csv to /content\n",
            "  0% 0.00/88.5k [00:00<?, ?B/s]\n",
            "100% 88.5k/88.5k [00:00<00:00, 94.2MB/s]\n",
            "Downloading Essay_Set_Descriptions.zip to /content\n",
            "  0% 0.00/214k [00:00<?, ?B/s]\n",
            "100% 214k/214k [00:00<00:00, 177MB/s]\n",
            "Downloading Training_Materials.zip to /content\n",
            " 87% 48.0M/55.0M [00:00<00:00, 30.7MB/s]\n",
            "100% 55.0M/55.0M [00:00<00:00, 59.5MB/s]\n",
            "Downloading test_set.tsv to /content\n",
            "100% 5.00M/5.02M [00:00<00:00, 39.5MB/s]\n",
            "100% 5.02M/5.02M [00:00<00:00, 31.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IeZosbrOpWuH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pandas import DataFrame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RFNRxVnGpf4b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = pd.read_csv('training_set_rel3.tsv', sep='\\t', encoding='ISO-8859-1')\n",
        "y = X['domain1_score']\n",
        "X = X.dropna(axis=1)\n",
        "X = X.drop(columns=['rater1_domain1', 'rater2_domain1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UaXrXNhKpno5",
        "colab_type": "code",
        "outputId": "375daa41-e8f0-4dd5-e46f-f4e456a2d198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "\n",
              "   domain1_score  \n",
              "0              8  \n",
              "1              9  \n",
              "2              7  \n",
              "3             10  \n",
              "4              8  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "8HsDb40YppzD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Pre-Processing the model\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJWYam76reHW",
        "colab_type": "code",
        "outputId": "cce7df4d-22eb-47e9-df09-b9b60fca2d15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt') # Sentence tokenizer\n",
        "nltk.download('stopwords') # English stop words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "LHrg8-X-rgAY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def essay_to_wordlist(essay_v, remove_stopwords):\n",
        "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
        "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v) #re.sub(pattern,repl,string) #replace all the sting not in tha range a-z with empy.\n",
        "    words = essay_v.lower().split()\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    return (words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_cHxReKsbcf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def essay_to_sentences(essay_v, remove_stopwords):\n",
        "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle') #sentence tokenizer\n",
        "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z1TQv2Mqs1bR",
        "colab_type": "code",
        "outputId": "07c4160c-6306-48f4-c0e1-156891aaa13b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "print(X['essay'][0])\n",
        "print(\"\\n\")\n",
        "wordlist = essay_to_wordlist(X['essay'][0],True)\n",
        "print(wordlist)\n",
        "print(len(wordlist))\n",
        "print(\"\\n\")\n",
        "Sentences = essay_to_sentences(X['essay'][0],True)\n",
        "print(Sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\n",
            "\n",
            "\n",
            "['dear', 'local', 'newspaper', 'think', 'effects', 'computers', 'people', 'great', 'learning', 'skills', 'affects', 'give', 'us', 'time', 'chat', 'friends', 'new', 'people', 'helps', 'us', 'learn', 'globe', 'astronomy', 'keeps', 'us', 'troble', 'thing', 'dont', 'think', 'would', 'feel', 'teenager', 'always', 'phone', 'friends', 'ever', 'time', 'chat', 'friends', 'buisness', 'partner', 'things', 'well', 'new', 'way', 'chat', 'computer', 'plenty', 'sites', 'internet', 'organization', 'organization', 'caps', 'facebook', 'myspace', 'ect', 'think', 'setting', 'meeting', 'boss', 'computer', 'teenager', 'fun', 'phone', 'rushing', 'get', 'cause', 'want', 'use', 'learn', 'countrys', 'states', 'outside', 'well', 'computer', 'internet', 'new', 'way', 'learn', 'going', 'time', 'might', 'think', 'child', 'spends', 'lot', 'time', 'computer', 'ask', 'question', 'economy', 'sea', 'floor', 'spreading', 'even', 'date', 'surprise', 'much', 'knows', 'believe', 'computer', 'much', 'interesting', 'class', 'day', 'reading', 'books', 'child', 'home', 'computer', 'local', 'library', 'better', 'friends', 'fresh', 'perpressured', 'something', 'know', 'isnt', 'right', 'might', 'know', 'child', 'caps', 'forbidde', 'hospital', 'bed', 'drive', 'rather', 'child', 'computer', 'learning', 'chatting', 'playing', 'games', 'safe', 'sound', 'home', 'community', 'place', 'hope', 'reached', 'point', 'understand', 'agree', 'computers', 'great', 'effects', 'child', 'gives', 'us', 'time', 'chat', 'friends', 'new', 'people', 'helps', 'us', 'learn', 'globe', 'believe', 'keeps', 'us', 'troble', 'thank', 'listening']\n",
            "166\n",
            "\n",
            "\n",
            "[['dear', 'local', 'newspaper', 'think', 'effects', 'computers', 'people', 'great', 'learning', 'skills', 'affects', 'give', 'us', 'time', 'chat', 'friends', 'new', 'people', 'helps', 'us', 'learn', 'globe', 'astronomy', 'keeps', 'us', 'troble'], ['thing'], ['dont', 'think'], ['would', 'feel', 'teenager', 'always', 'phone', 'friends'], ['ever', 'time', 'chat', 'friends', 'buisness', 'partner', 'things'], ['well', 'new', 'way', 'chat', 'computer', 'plenty', 'sites', 'internet', 'organization', 'organization', 'caps', 'facebook', 'myspace', 'ect'], ['think', 'setting', 'meeting', 'boss', 'computer', 'teenager', 'fun', 'phone', 'rushing', 'get', 'cause', 'want', 'use'], ['learn', 'countrys', 'states', 'outside'], ['well', 'computer', 'internet', 'new', 'way', 'learn', 'going', 'time'], ['might', 'think', 'child', 'spends', 'lot', 'time', 'computer', 'ask', 'question', 'economy', 'sea', 'floor', 'spreading', 'even', 'date', 'surprise', 'much', 'knows'], ['believe', 'computer', 'much', 'interesting', 'class', 'day', 'reading', 'books'], ['child', 'home', 'computer', 'local', 'library', 'better', 'friends', 'fresh', 'perpressured', 'something', 'know', 'isnt', 'right'], ['might', 'know', 'child', 'caps', 'forbidde', 'hospital', 'bed', 'drive'], ['rather', 'child', 'computer', 'learning', 'chatting', 'playing', 'games', 'safe', 'sound', 'home', 'community', 'place'], ['hope', 'reached', 'point', 'understand', 'agree', 'computers', 'great', 'effects', 'child', 'gives', 'us', 'time', 'chat', 'friends', 'new', 'people', 'helps', 'us', 'learn', 'globe', 'believe', 'keeps', 'us', 'troble'], ['thank', 'listening']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TvWEXCKOk1bv",
        "colab_type": "code",
        "outputId": "f503e050-aeaa-4890-8dd7-8c3acc7c941d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/fb/7586e11ff9205c9be9d11d376fcb6990ec4bdfae0a35663fb1ada7e3c10f/emoji-0.5.1-py3-none-any.whl\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YkFP5kmBlOBK",
        "colab_type": "code",
        "outputId": "34ea7bff-db0b-4422-ec9a-a7e778d6a54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip \"/gdrive/My Drive/Deep learning/Essay_Scoring_V2/data_files/glove.6B.50d.txt.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /gdrive/My Drive/Deep learning/Essay_Scoring_V2/data_files/glove.6B.50d.txt.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._glove.6B.50d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bLNfOa-0h940",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from Essay_Scoring_V2.emo_utils import *\n",
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/content/glove.6B.50d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TVHIwQ8oJWmb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For every word in an essay we will acess its feature vector in makeFeatureVec() using glove vector for word representation.We will add all the feature vector and take average.Since we are using glove of 50 dimension, each essay will be represented with a (1,50) dimensional vector."
      ]
    },
    {
      "metadata": {
        "id": "oyDLy3O5leAG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def makeFeatureVec(words,  num_features):\n",
        "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\") # to store the feature vector of each word\n",
        "    num_words = 0\n",
        "    for word in words:\n",
        "        if word in word_to_index:\n",
        "            num_words += 1\n",
        "            featureVec = np.add(featureVec,word_to_vec_map[word])        \n",
        "    featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec\n",
        "\n",
        "def getAvgFeatureVecs(essays,num_features):\n",
        "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for essay in essays:\n",
        "        essayFeatureVecs[counter] = makeFeatureVec(essay,num_features)\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2MzvKbq239U7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten,Bidirectional\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(50, return_sequences=True,recurrent_dropout=0.4), input_shape=(1,50), merge_mode='concat'))\n",
        "    #model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNbFiw_XTpOQ",
        "colab_type": "code",
        "outputId": "fbdc0a02-b4f2-4c21-b611-45bdd9e1a465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27149
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "results = []\n",
        "y_pred_list = []\n",
        "cv_data =cv.split(X)\n",
        "count = 1\n",
        "print(cv_data)\n",
        "for traincv, testcv in cv_data:\n",
        "  \n",
        "  print(\"\\n--------Fold {}--------\\n\".format(count))\n",
        "  X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
        "  train_essays = X_train['essay']\n",
        "  test_essays = X_test['essay']\n",
        "  num_features = 50 \n",
        "  min_word_count = 40\n",
        "  num_workers = 4\n",
        "  context = 10\n",
        "  downsampling = 1e-3\n",
        "  clean_train_essays = []\n",
        "  \n",
        "  for essay_v in train_essays:\n",
        "    clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords= True))\n",
        "  trainDataVecs = getAvgFeatureVecs(clean_train_essays,num_features)\n",
        "    \n",
        "  clean_test_essays = []\n",
        "    \n",
        "  for essay_v in test_essays:\n",
        "    clean_test_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True ))\n",
        "  testDataVecs = getAvgFeatureVecs(clean_test_essays,num_features)\n",
        "  \n",
        "  trainDataVecs = np.array(trainDataVecs)\n",
        "  \n",
        "  testDataVecs = np.array(testDataVecs)\n",
        "  \n",
        "  # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
        "  \n",
        "  trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "  \n",
        "  testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "  \n",
        "  lstm_model = get_model()\n",
        "  lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=150)\n",
        "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
        "  y_pred = lstm_model.predict(testDataVecs)\n",
        "    \n",
        "    \n",
        "  y_pred = np.around(y_pred)\n",
        "    \n",
        "  result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
        "  print(\"Kappa Score: {}\".format(result))\n",
        "  results.append(result)\n",
        "  count = count + 1\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<generator object _BaseKFold.split at 0x7fc1bfdfbf68>\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_12 (Bidirectio (None, 1, 100)            40400     \n",
            "_________________________________________________________________\n",
            "lstm_25 (LSTM)               (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 82,705\n",
            "Trainable params: 82,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "10380/10380 [==============================] - 9s 826us/step - loss: 75.8590 - mean_absolute_error: 5.1505\n",
            "Epoch 2/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 47.1378 - mean_absolute_error: 3.8898\n",
            "Epoch 3/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 37.2078 - mean_absolute_error: 3.5589\n",
            "Epoch 4/150\n",
            "10380/10380 [==============================] - 2s 152us/step - loss: 32.1894 - mean_absolute_error: 3.3441\n",
            "Epoch 5/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 28.4159 - mean_absolute_error: 3.1477\n",
            "Epoch 6/150\n",
            "10380/10380 [==============================] - 1s 144us/step - loss: 26.8277 - mean_absolute_error: 3.0124\n",
            "Epoch 7/150\n",
            "10380/10380 [==============================] - 1s 138us/step - loss: 24.6961 - mean_absolute_error: 2.8670\n",
            "Epoch 8/150\n",
            "10380/10380 [==============================] - 1s 141us/step - loss: 23.0914 - mean_absolute_error: 2.7506\n",
            "Epoch 9/150\n",
            "10380/10380 [==============================] - 1s 141us/step - loss: 21.4443 - mean_absolute_error: 2.6293\n",
            "Epoch 10/150\n",
            "10380/10380 [==============================] - 1s 140us/step - loss: 19.6325 - mean_absolute_error: 2.5120\n",
            "Epoch 11/150\n",
            "10380/10380 [==============================] - 1s 143us/step - loss: 18.6253 - mean_absolute_error: 2.4341\n",
            "Epoch 12/150\n",
            "10380/10380 [==============================] - 1s 142us/step - loss: 17.3921 - mean_absolute_error: 2.3366\n",
            "Epoch 13/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 17.1101 - mean_absolute_error: 2.3116\n",
            "Epoch 14/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 16.4697 - mean_absolute_error: 2.2768\n",
            "Epoch 15/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 15.3359 - mean_absolute_error: 2.1993\n",
            "Epoch 16/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 15.4841 - mean_absolute_error: 2.1985\n",
            "Epoch 17/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 15.0991 - mean_absolute_error: 2.1576\n",
            "Epoch 18/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 14.4740 - mean_absolute_error: 2.1194\n",
            "Epoch 19/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 14.3852 - mean_absolute_error: 2.1021\n",
            "Epoch 20/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 13.8845 - mean_absolute_error: 2.0672\n",
            "Epoch 21/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 13.1550 - mean_absolute_error: 2.0340\n",
            "Epoch 22/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 13.3857 - mean_absolute_error: 2.0437\n",
            "Epoch 23/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 12.9067 - mean_absolute_error: 2.0093\n",
            "Epoch 24/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 12.7257 - mean_absolute_error: 1.9797\n",
            "Epoch 25/150\n",
            "10380/10380 [==============================] - 2s 152us/step - loss: 12.8085 - mean_absolute_error: 1.9940\n",
            "Epoch 26/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 12.4084 - mean_absolute_error: 1.9584\n",
            "Epoch 27/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 12.3385 - mean_absolute_error: 1.9675\n",
            "Epoch 28/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 12.2251 - mean_absolute_error: 1.9399\n",
            "Epoch 29/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 11.9219 - mean_absolute_error: 1.9148\n",
            "Epoch 30/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 11.2811 - mean_absolute_error: 1.8749\n",
            "Epoch 31/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 11.2901 - mean_absolute_error: 1.8669\n",
            "Epoch 32/150\n",
            "10380/10380 [==============================] - 1s 141us/step - loss: 11.4121 - mean_absolute_error: 1.8797\n",
            "Epoch 33/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 11.4130 - mean_absolute_error: 1.8583\n",
            "Epoch 34/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 10.8792 - mean_absolute_error: 1.8362\n",
            "Epoch 35/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 11.3006 - mean_absolute_error: 1.8539\n",
            "Epoch 36/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 11.1750 - mean_absolute_error: 1.8285\n",
            "Epoch 37/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 10.5093 - mean_absolute_error: 1.8082\n",
            "Epoch 38/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 10.6034 - mean_absolute_error: 1.7943\n",
            "Epoch 39/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 10.7045 - mean_absolute_error: 1.8018\n",
            "Epoch 40/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 10.6049 - mean_absolute_error: 1.7959\n",
            "Epoch 41/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 10.1771 - mean_absolute_error: 1.7570\n",
            "Epoch 42/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 10.6029 - mean_absolute_error: 1.7859\n",
            "Epoch 43/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 10.2524 - mean_absolute_error: 1.7571\n",
            "Epoch 44/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 9.8842 - mean_absolute_error: 1.7455\n",
            "Epoch 45/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 9.6809 - mean_absolute_error: 1.7316\n",
            "Epoch 46/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 9.7748 - mean_absolute_error: 1.7317\n",
            "Epoch 47/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 9.7757 - mean_absolute_error: 1.7278\n",
            "Epoch 48/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 9.7341 - mean_absolute_error: 1.7407\n",
            "Epoch 49/150\n",
            "10380/10380 [==============================] - 1s 143us/step - loss: 9.5890 - mean_absolute_error: 1.7168\n",
            "Epoch 50/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 9.6576 - mean_absolute_error: 1.7176\n",
            "Epoch 51/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 9.5602 - mean_absolute_error: 1.7054\n",
            "Epoch 52/150\n",
            "10380/10380 [==============================] - 1s 143us/step - loss: 9.1372 - mean_absolute_error: 1.6924\n",
            "Epoch 53/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 9.5119 - mean_absolute_error: 1.6940\n",
            "Epoch 54/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 9.2796 - mean_absolute_error: 1.6906\n",
            "Epoch 55/150\n",
            "10380/10380 [==============================] - 2s 152us/step - loss: 9.3067 - mean_absolute_error: 1.6903\n",
            "Epoch 56/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 9.1341 - mean_absolute_error: 1.6668\n",
            "Epoch 57/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 8.9462 - mean_absolute_error: 1.6494\n",
            "Epoch 58/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 8.8247 - mean_absolute_error: 1.6435\n",
            "Epoch 59/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 9.1392 - mean_absolute_error: 1.6724\n",
            "Epoch 60/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 8.9176 - mean_absolute_error: 1.6559\n",
            "Epoch 61/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 9.0868 - mean_absolute_error: 1.6689\n",
            "Epoch 62/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 8.7410 - mean_absolute_error: 1.6558\n",
            "Epoch 63/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 8.8610 - mean_absolute_error: 1.6539\n",
            "Epoch 64/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 9.1524 - mean_absolute_error: 1.6572\n",
            "Epoch 65/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 8.7724 - mean_absolute_error: 1.6403\n",
            "Epoch 66/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 8.4444 - mean_absolute_error: 1.6272\n",
            "Epoch 67/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 8.7668 - mean_absolute_error: 1.6482\n",
            "Epoch 68/150\n",
            "10380/10380 [==============================] - 1s 144us/step - loss: 8.8447 - mean_absolute_error: 1.6464\n",
            "Epoch 69/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 8.2162 - mean_absolute_error: 1.6031\n",
            "Epoch 70/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 8.5470 - mean_absolute_error: 1.6134\n",
            "Epoch 71/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 8.5527 - mean_absolute_error: 1.6227\n",
            "Epoch 72/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 8.1046 - mean_absolute_error: 1.5981\n",
            "Epoch 73/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 8.5428 - mean_absolute_error: 1.6237\n",
            "Epoch 74/150\n",
            "10380/10380 [==============================] - 2s 167us/step - loss: 8.3032 - mean_absolute_error: 1.6104\n",
            "Epoch 75/150\n",
            "10380/10380 [==============================] - 2s 171us/step - loss: 7.9861 - mean_absolute_error: 1.5941\n",
            "Epoch 76/150\n",
            "10380/10380 [==============================] - 2s 167us/step - loss: 8.0043 - mean_absolute_error: 1.5930\n",
            "Epoch 77/150\n",
            "10380/10380 [==============================] - 2s 153us/step - loss: 8.6149 - mean_absolute_error: 1.6209\n",
            "Epoch 78/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 8.3890 - mean_absolute_error: 1.5986\n",
            "Epoch 79/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 7.7709 - mean_absolute_error: 1.5714\n",
            "Epoch 80/150\n",
            "10380/10380 [==============================] - 2s 154us/step - loss: 8.4035 - mean_absolute_error: 1.6083\n",
            "Epoch 81/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 7.9343 - mean_absolute_error: 1.5747\n",
            "Epoch 82/150\n",
            "10380/10380 [==============================] - 2s 153us/step - loss: 8.0696 - mean_absolute_error: 1.5837\n",
            "Epoch 83/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 8.1099 - mean_absolute_error: 1.5962\n",
            "Epoch 84/150\n",
            "10380/10380 [==============================] - 2s 152us/step - loss: 7.8099 - mean_absolute_error: 1.5526\n",
            "Epoch 85/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 7.7498 - mean_absolute_error: 1.5584\n",
            "Epoch 86/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 7.8442 - mean_absolute_error: 1.5667\n",
            "Epoch 87/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 7.8608 - mean_absolute_error: 1.5740\n",
            "Epoch 88/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 7.8554 - mean_absolute_error: 1.5643\n",
            "Epoch 89/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 8.0190 - mean_absolute_error: 1.5685\n",
            "Epoch 90/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 7.6283 - mean_absolute_error: 1.5498\n",
            "Epoch 91/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 7.8106 - mean_absolute_error: 1.5643\n",
            "Epoch 92/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 7.8396 - mean_absolute_error: 1.5504\n",
            "Epoch 93/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 7.7527 - mean_absolute_error: 1.5520\n",
            "Epoch 94/150\n",
            "10380/10380 [==============================] - 2s 155us/step - loss: 7.5512 - mean_absolute_error: 1.5435\n",
            "Epoch 95/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 7.5863 - mean_absolute_error: 1.5372\n",
            "Epoch 96/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 7.4346 - mean_absolute_error: 1.5263\n",
            "Epoch 97/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 7.4323 - mean_absolute_error: 1.5337\n",
            "Epoch 98/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 7.3111 - mean_absolute_error: 1.5231\n",
            "Epoch 99/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 7.4431 - mean_absolute_error: 1.5314\n",
            "Epoch 100/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 7.3992 - mean_absolute_error: 1.5287\n",
            "Epoch 101/150\n",
            "10380/10380 [==============================] - 2s 153us/step - loss: 7.3255 - mean_absolute_error: 1.5255\n",
            "Epoch 102/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 7.0406 - mean_absolute_error: 1.4962\n",
            "Epoch 103/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 7.6089 - mean_absolute_error: 1.5523\n",
            "Epoch 104/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 7.2575 - mean_absolute_error: 1.5173\n",
            "Epoch 105/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 7.3951 - mean_absolute_error: 1.5152\n",
            "Epoch 106/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 7.0822 - mean_absolute_error: 1.5083\n",
            "Epoch 107/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 7.3522 - mean_absolute_error: 1.5272\n",
            "Epoch 108/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 7.4071 - mean_absolute_error: 1.5159\n",
            "Epoch 109/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 7.0674 - mean_absolute_error: 1.4948\n",
            "Epoch 110/150\n",
            "10380/10380 [==============================] - 2s 145us/step - loss: 7.0668 - mean_absolute_error: 1.4991\n",
            "Epoch 111/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 7.0008 - mean_absolute_error: 1.4989\n",
            "Epoch 112/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 7.3259 - mean_absolute_error: 1.5031\n",
            "Epoch 113/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 7.1790 - mean_absolute_error: 1.4975\n",
            "Epoch 114/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 6.8533 - mean_absolute_error: 1.4748\n",
            "Epoch 115/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 7.1172 - mean_absolute_error: 1.4872\n",
            "Epoch 116/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 7.1038 - mean_absolute_error: 1.4888\n",
            "Epoch 117/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 6.8294 - mean_absolute_error: 1.4700\n",
            "Epoch 118/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 7.1600 - mean_absolute_error: 1.5035\n",
            "Epoch 119/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 6.9612 - mean_absolute_error: 1.4836\n",
            "Epoch 120/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 6.6878 - mean_absolute_error: 1.4697\n",
            "Epoch 121/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 7.0883 - mean_absolute_error: 1.4817\n",
            "Epoch 122/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 6.9196 - mean_absolute_error: 1.4731\n",
            "Epoch 123/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 6.8764 - mean_absolute_error: 1.4760\n",
            "Epoch 124/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 6.8410 - mean_absolute_error: 1.4805\n",
            "Epoch 125/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 6.7630 - mean_absolute_error: 1.4506\n",
            "Epoch 126/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 6.6344 - mean_absolute_error: 1.4623\n",
            "Epoch 127/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 6.9570 - mean_absolute_error: 1.4818\n",
            "Epoch 128/150\n",
            "10380/10380 [==============================] - 2s 148us/step - loss: 6.8889 - mean_absolute_error: 1.4708\n",
            "Epoch 129/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 6.7358 - mean_absolute_error: 1.4623\n",
            "Epoch 130/150\n",
            "10380/10380 [==============================] - 2s 152us/step - loss: 6.7565 - mean_absolute_error: 1.4579\n",
            "Epoch 131/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 6.7122 - mean_absolute_error: 1.4612\n",
            "Epoch 132/150\n",
            "10380/10380 [==============================] - 2s 149us/step - loss: 6.5691 - mean_absolute_error: 1.4419\n",
            "Epoch 133/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 6.3905 - mean_absolute_error: 1.4298\n",
            "Epoch 134/150\n",
            "10380/10380 [==============================] - 1s 144us/step - loss: 6.5083 - mean_absolute_error: 1.4477\n",
            "Epoch 135/150\n",
            "10380/10380 [==============================] - 1s 141us/step - loss: 6.4087 - mean_absolute_error: 1.4402\n",
            "Epoch 136/150\n",
            "10380/10380 [==============================] - 2s 147us/step - loss: 6.6830 - mean_absolute_error: 1.4476\n",
            "Epoch 137/150\n",
            "10380/10380 [==============================] - 2s 146us/step - loss: 6.4957 - mean_absolute_error: 1.4458\n",
            "Epoch 138/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 6.5472 - mean_absolute_error: 1.4448\n",
            "Epoch 139/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 6.5632 - mean_absolute_error: 1.4394\n",
            "Epoch 140/150\n",
            "10380/10380 [==============================] - 2s 152us/step - loss: 6.3638 - mean_absolute_error: 1.4293\n",
            "Epoch 141/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 6.4552 - mean_absolute_error: 1.4328\n",
            "Epoch 142/150\n",
            "10380/10380 [==============================] - 2s 153us/step - loss: 6.4890 - mean_absolute_error: 1.4484\n",
            "Epoch 143/150\n",
            "10380/10380 [==============================] - 2s 152us/step - loss: 6.1703 - mean_absolute_error: 1.4237\n",
            "Epoch 144/150\n",
            "10380/10380 [==============================] - 2s 154us/step - loss: 6.4614 - mean_absolute_error: 1.4379\n",
            "Epoch 145/150\n",
            "10380/10380 [==============================] - 2s 151us/step - loss: 6.3862 - mean_absolute_error: 1.4348\n",
            "Epoch 146/150\n",
            "10380/10380 [==============================] - 2s 150us/step - loss: 6.3730 - mean_absolute_error: 1.4304\n",
            "Epoch 147/150\n",
            "10380/10380 [==============================] - 2s 153us/step - loss: 6.3452 - mean_absolute_error: 1.4206\n",
            "Epoch 148/150\n",
            "10380/10380 [==============================] - 2s 153us/step - loss: 6.4511 - mean_absolute_error: 1.4359\n",
            "Epoch 149/150\n",
            "10380/10380 [==============================] - 2s 152us/step - loss: 6.2898 - mean_absolute_error: 1.4246\n",
            "Epoch 150/150\n",
            "10380/10380 [==============================] - 2s 152us/step - loss: 6.3274 - mean_absolute_error: 1.4169\n",
            "Kappa Score: 0.9503166453069691\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_13 (Bidirectio (None, 1, 100)            40400     \n",
            "_________________________________________________________________\n",
            "lstm_27 (LSTM)               (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 82,705\n",
            "Trainable params: 82,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "10381/10381 [==============================] - 9s 881us/step - loss: 73.7471 - mean_absolute_error: 5.0977\n",
            "Epoch 2/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 46.0677 - mean_absolute_error: 3.9080\n",
            "Epoch 3/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 36.1856 - mean_absolute_error: 3.5363\n",
            "Epoch 4/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 31.0394 - mean_absolute_error: 3.3327\n",
            "Epoch 5/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 28.0793 - mean_absolute_error: 3.1679\n",
            "Epoch 6/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 25.6149 - mean_absolute_error: 2.9829\n",
            "Epoch 7/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 23.7634 - mean_absolute_error: 2.8467\n",
            "Epoch 8/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 22.3112 - mean_absolute_error: 2.7340\n",
            "Epoch 9/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 21.0550 - mean_absolute_error: 2.6412\n",
            "Epoch 10/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 19.5837 - mean_absolute_error: 2.5151\n",
            "Epoch 11/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 18.1366 - mean_absolute_error: 2.4121\n",
            "Epoch 12/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 17.7373 - mean_absolute_error: 2.3723\n",
            "Epoch 13/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 16.9323 - mean_absolute_error: 2.3042\n",
            "Epoch 14/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 15.6420 - mean_absolute_error: 2.2188\n",
            "Epoch 15/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 15.3992 - mean_absolute_error: 2.1969\n",
            "Epoch 16/150\n",
            "10381/10381 [==============================] - 2s 168us/step - loss: 14.8046 - mean_absolute_error: 2.1582\n",
            "Epoch 17/150\n",
            "10381/10381 [==============================] - 2s 171us/step - loss: 14.0010 - mean_absolute_error: 2.1104\n",
            "Epoch 18/150\n",
            "10381/10381 [==============================] - 2s 169us/step - loss: 14.2554 - mean_absolute_error: 2.1205\n",
            "Epoch 19/150\n",
            "10381/10381 [==============================] - 2s 168us/step - loss: 13.5726 - mean_absolute_error: 2.0734\n",
            "Epoch 20/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 13.1297 - mean_absolute_error: 2.0574\n",
            "Epoch 21/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 13.1029 - mean_absolute_error: 2.0257\n",
            "Epoch 22/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 12.7559 - mean_absolute_error: 1.9968\n",
            "Epoch 23/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 12.5845 - mean_absolute_error: 1.9876\n",
            "Epoch 24/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 12.1984 - mean_absolute_error: 1.9487\n",
            "Epoch 25/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 11.9076 - mean_absolute_error: 1.9184\n",
            "Epoch 26/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 12.3791 - mean_absolute_error: 1.9471\n",
            "Epoch 27/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 11.7530 - mean_absolute_error: 1.8945\n",
            "Epoch 28/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 11.6735 - mean_absolute_error: 1.9043\n",
            "Epoch 29/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 11.2254 - mean_absolute_error: 1.8680\n",
            "Epoch 30/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 11.0429 - mean_absolute_error: 1.8581\n",
            "Epoch 31/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 10.9767 - mean_absolute_error: 1.8338\n",
            "Epoch 32/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 11.0752 - mean_absolute_error: 1.8385\n",
            "Epoch 33/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 10.8608 - mean_absolute_error: 1.8352\n",
            "Epoch 34/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 10.9792 - mean_absolute_error: 1.8065\n",
            "Epoch 35/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 10.5903 - mean_absolute_error: 1.8094\n",
            "Epoch 36/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 10.4623 - mean_absolute_error: 1.8047\n",
            "Epoch 37/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 10.4198 - mean_absolute_error: 1.7835\n",
            "Epoch 38/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 10.1305 - mean_absolute_error: 1.7635\n",
            "Epoch 39/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 9.9543 - mean_absolute_error: 1.7560\n",
            "Epoch 40/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 10.2908 - mean_absolute_error: 1.7490\n",
            "Epoch 41/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 10.0310 - mean_absolute_error: 1.7549\n",
            "Epoch 42/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 9.8987 - mean_absolute_error: 1.7296\n",
            "Epoch 43/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 10.0037 - mean_absolute_error: 1.7329\n",
            "Epoch 44/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 9.8041 - mean_absolute_error: 1.7077\n",
            "Epoch 45/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 9.3409 - mean_absolute_error: 1.6928\n",
            "Epoch 46/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 9.2677 - mean_absolute_error: 1.6904\n",
            "Epoch 47/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 9.3917 - mean_absolute_error: 1.6956\n",
            "Epoch 48/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 9.1044 - mean_absolute_error: 1.6807\n",
            "Epoch 49/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 9.6080 - mean_absolute_error: 1.7026\n",
            "Epoch 50/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 9.2406 - mean_absolute_error: 1.6780\n",
            "Epoch 51/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 9.1293 - mean_absolute_error: 1.6779\n",
            "Epoch 52/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 9.1826 - mean_absolute_error: 1.6856\n",
            "Epoch 53/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.8278 - mean_absolute_error: 1.6446\n",
            "Epoch 54/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 8.6965 - mean_absolute_error: 1.6456\n",
            "Epoch 55/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 9.0442 - mean_absolute_error: 1.6550\n",
            "Epoch 56/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 8.8332 - mean_absolute_error: 1.6462\n",
            "Epoch 57/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 9.0204 - mean_absolute_error: 1.6687\n",
            "Epoch 58/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 8.6491 - mean_absolute_error: 1.6198\n",
            "Epoch 59/150\n",
            "10381/10381 [==============================] - 2s 145us/step - loss: 8.5893 - mean_absolute_error: 1.6225\n",
            "Epoch 60/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.8571 - mean_absolute_error: 1.6384\n",
            "Epoch 61/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.8201 - mean_absolute_error: 1.6390\n",
            "Epoch 62/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 8.5981 - mean_absolute_error: 1.6225\n",
            "Epoch 63/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 8.5469 - mean_absolute_error: 1.6155\n",
            "Epoch 64/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 8.6075 - mean_absolute_error: 1.6264\n",
            "Epoch 65/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 8.1049 - mean_absolute_error: 1.5849\n",
            "Epoch 66/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 8.5047 - mean_absolute_error: 1.6146\n",
            "Epoch 67/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 8.5797 - mean_absolute_error: 1.6190\n",
            "Epoch 68/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 8.3109 - mean_absolute_error: 1.6142\n",
            "Epoch 69/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 8.2795 - mean_absolute_error: 1.5938\n",
            "Epoch 70/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 8.2684 - mean_absolute_error: 1.5955\n",
            "Epoch 71/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 8.1998 - mean_absolute_error: 1.5906\n",
            "Epoch 72/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 8.2254 - mean_absolute_error: 1.5849\n",
            "Epoch 73/150\n",
            "10381/10381 [==============================] - 1s 144us/step - loss: 8.2920 - mean_absolute_error: 1.5871\n",
            "Epoch 74/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 8.3026 - mean_absolute_error: 1.5787\n",
            "Epoch 75/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 7.7896 - mean_absolute_error: 1.5581\n",
            "Epoch 76/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.8361 - mean_absolute_error: 1.5620\n",
            "Epoch 77/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.7509 - mean_absolute_error: 1.5575\n",
            "Epoch 78/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 8.3956 - mean_absolute_error: 1.5931\n",
            "Epoch 79/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.6076 - mean_absolute_error: 1.5400\n",
            "Epoch 80/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.8842 - mean_absolute_error: 1.5473\n",
            "Epoch 81/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.5081 - mean_absolute_error: 1.5421\n",
            "Epoch 82/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.9322 - mean_absolute_error: 1.5496\n",
            "Epoch 83/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 7.7472 - mean_absolute_error: 1.5519\n",
            "Epoch 84/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 7.3119 - mean_absolute_error: 1.5122\n",
            "Epoch 85/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 7.4608 - mean_absolute_error: 1.5266\n",
            "Epoch 86/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.7064 - mean_absolute_error: 1.5430\n",
            "Epoch 87/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.5659 - mean_absolute_error: 1.5282\n",
            "Epoch 88/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.3530 - mean_absolute_error: 1.5345\n",
            "Epoch 89/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 7.5654 - mean_absolute_error: 1.5224\n",
            "Epoch 90/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.8977 - mean_absolute_error: 1.5455\n",
            "Epoch 91/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 7.5421 - mean_absolute_error: 1.5378\n",
            "Epoch 92/150\n",
            "10381/10381 [==============================] - 2s 145us/step - loss: 7.2739 - mean_absolute_error: 1.5049\n",
            "Epoch 93/150\n",
            "10381/10381 [==============================] - 1s 144us/step - loss: 7.4031 - mean_absolute_error: 1.5093\n",
            "Epoch 94/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 7.5176 - mean_absolute_error: 1.5219\n",
            "Epoch 95/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.2435 - mean_absolute_error: 1.5051\n",
            "Epoch 96/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.3837 - mean_absolute_error: 1.5136\n",
            "Epoch 97/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.0386 - mean_absolute_error: 1.4923\n",
            "Epoch 98/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.0124 - mean_absolute_error: 1.4762\n",
            "Epoch 99/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 7.0313 - mean_absolute_error: 1.4806\n",
            "Epoch 100/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.1232 - mean_absolute_error: 1.4945\n",
            "Epoch 101/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.2060 - mean_absolute_error: 1.5011\n",
            "Epoch 102/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.2158 - mean_absolute_error: 1.4952\n",
            "Epoch 103/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.0873 - mean_absolute_error: 1.4875\n",
            "Epoch 104/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.1455 - mean_absolute_error: 1.4727\n",
            "Epoch 105/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.9913 - mean_absolute_error: 1.4921\n",
            "Epoch 106/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 7.1284 - mean_absolute_error: 1.5030\n",
            "Epoch 107/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 7.1687 - mean_absolute_error: 1.4982\n",
            "Epoch 108/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 7.2433 - mean_absolute_error: 1.4818\n",
            "Epoch 109/150\n",
            "10381/10381 [==============================] - 2s 165us/step - loss: 6.9769 - mean_absolute_error: 1.4795\n",
            "Epoch 110/150\n",
            "10381/10381 [==============================] - 2s 170us/step - loss: 6.9876 - mean_absolute_error: 1.4892\n",
            "Epoch 111/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 6.9564 - mean_absolute_error: 1.4796\n",
            "Epoch 112/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.1904 - mean_absolute_error: 1.4791\n",
            "Epoch 113/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 6.9742 - mean_absolute_error: 1.4715\n",
            "Epoch 114/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.8155 - mean_absolute_error: 1.4700\n",
            "Epoch 115/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.9721 - mean_absolute_error: 1.4676\n",
            "Epoch 116/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.7494 - mean_absolute_error: 1.4564\n",
            "Epoch 117/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.9090 - mean_absolute_error: 1.4659\n",
            "Epoch 118/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.6987 - mean_absolute_error: 1.4624\n",
            "Epoch 119/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.8387 - mean_absolute_error: 1.4540\n",
            "Epoch 120/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.0466 - mean_absolute_error: 1.4747\n",
            "Epoch 121/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 6.7089 - mean_absolute_error: 1.4450\n",
            "Epoch 122/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.7023 - mean_absolute_error: 1.4367\n",
            "Epoch 123/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 6.7574 - mean_absolute_error: 1.4576\n",
            "Epoch 124/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 6.5256 - mean_absolute_error: 1.4310\n",
            "Epoch 125/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 6.6285 - mean_absolute_error: 1.4444\n",
            "Epoch 126/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.8240 - mean_absolute_error: 1.4665\n",
            "Epoch 127/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.4254 - mean_absolute_error: 1.4290\n",
            "Epoch 128/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.5882 - mean_absolute_error: 1.4357\n",
            "Epoch 129/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.5757 - mean_absolute_error: 1.4371\n",
            "Epoch 130/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 6.3484 - mean_absolute_error: 1.4181\n",
            "Epoch 131/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 6.4829 - mean_absolute_error: 1.4262\n",
            "Epoch 132/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.5436 - mean_absolute_error: 1.4287\n",
            "Epoch 133/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 6.3958 - mean_absolute_error: 1.4322\n",
            "Epoch 134/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 6.3712 - mean_absolute_error: 1.4209\n",
            "Epoch 135/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 6.4082 - mean_absolute_error: 1.4275\n",
            "Epoch 136/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.5159 - mean_absolute_error: 1.4236\n",
            "Epoch 137/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.2766 - mean_absolute_error: 1.4061\n",
            "Epoch 138/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 6.1636 - mean_absolute_error: 1.4002\n",
            "Epoch 139/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.1588 - mean_absolute_error: 1.4048\n",
            "Epoch 140/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.3977 - mean_absolute_error: 1.4161\n",
            "Epoch 141/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 6.1743 - mean_absolute_error: 1.4007\n",
            "Epoch 142/150\n",
            "10381/10381 [==============================] - 2s 145us/step - loss: 6.1289 - mean_absolute_error: 1.3987\n",
            "Epoch 143/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 6.1037 - mean_absolute_error: 1.3862\n",
            "Epoch 144/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.0336 - mean_absolute_error: 1.3919\n",
            "Epoch 145/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.3583 - mean_absolute_error: 1.4121\n",
            "Epoch 146/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 6.2274 - mean_absolute_error: 1.3930\n",
            "Epoch 147/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 5.9837 - mean_absolute_error: 1.3980\n",
            "Epoch 148/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 5.9886 - mean_absolute_error: 1.3909\n",
            "Epoch 149/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.2903 - mean_absolute_error: 1.4170\n",
            "Epoch 150/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.4167 - mean_absolute_error: 1.4092\n",
            "Kappa Score: 0.9448699239791082\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_14 (Bidirectio (None, 1, 100)            40400     \n",
            "_________________________________________________________________\n",
            "lstm_29 (LSTM)               (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 82,705\n",
            "Trainable params: 82,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "10381/10381 [==============================] - 10s 925us/step - loss: 76.0310 - mean_absolute_error: 5.1387\n",
            "Epoch 2/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 46.5821 - mean_absolute_error: 3.9043\n",
            "Epoch 3/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 36.8623 - mean_absolute_error: 3.5670\n",
            "Epoch 4/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 31.4784 - mean_absolute_error: 3.3518\n",
            "Epoch 5/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 29.7957 - mean_absolute_error: 3.2212\n",
            "Epoch 6/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 26.6338 - mean_absolute_error: 3.0201\n",
            "Epoch 7/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 24.7431 - mean_absolute_error: 2.8824\n",
            "Epoch 8/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 23.3024 - mean_absolute_error: 2.7647\n",
            "Epoch 9/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 21.2053 - mean_absolute_error: 2.6216\n",
            "Epoch 10/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 20.0487 - mean_absolute_error: 2.5482\n",
            "Epoch 11/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 18.3707 - mean_absolute_error: 2.4270\n",
            "Epoch 12/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 17.4281 - mean_absolute_error: 2.3563\n",
            "Epoch 13/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 16.5363 - mean_absolute_error: 2.3073\n",
            "Epoch 14/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 16.1130 - mean_absolute_error: 2.2782\n",
            "Epoch 15/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 15.3753 - mean_absolute_error: 2.2237\n",
            "Epoch 16/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 14.5759 - mean_absolute_error: 2.1579\n",
            "Epoch 17/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 14.3543 - mean_absolute_error: 2.1464\n",
            "Epoch 18/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 14.0424 - mean_absolute_error: 2.1184\n",
            "Epoch 19/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 13.9670 - mean_absolute_error: 2.1076\n",
            "Epoch 20/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 13.4175 - mean_absolute_error: 2.0503\n",
            "Epoch 21/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 13.2171 - mean_absolute_error: 2.0500\n",
            "Epoch 22/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 13.0114 - mean_absolute_error: 2.0256\n",
            "Epoch 23/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 12.8947 - mean_absolute_error: 2.0081\n",
            "Epoch 24/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 12.6604 - mean_absolute_error: 1.9823\n",
            "Epoch 25/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 12.6053 - mean_absolute_error: 1.9739\n",
            "Epoch 26/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 11.9489 - mean_absolute_error: 1.9517\n",
            "Epoch 27/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 11.8206 - mean_absolute_error: 1.9236\n",
            "Epoch 28/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 11.9043 - mean_absolute_error: 1.9093\n",
            "Epoch 29/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 11.7028 - mean_absolute_error: 1.9095\n",
            "Epoch 30/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 11.3345 - mean_absolute_error: 1.8771\n",
            "Epoch 31/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 11.4827 - mean_absolute_error: 1.8739\n",
            "Epoch 32/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 11.0853 - mean_absolute_error: 1.8605\n",
            "Epoch 33/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 11.2051 - mean_absolute_error: 1.8450\n",
            "Epoch 34/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 11.2756 - mean_absolute_error: 1.8483\n",
            "Epoch 35/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 10.8207 - mean_absolute_error: 1.8121\n",
            "Epoch 36/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 10.8388 - mean_absolute_error: 1.8169\n",
            "Epoch 37/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 10.6809 - mean_absolute_error: 1.8083\n",
            "Epoch 38/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 10.5949 - mean_absolute_error: 1.8126\n",
            "Epoch 39/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 10.3640 - mean_absolute_error: 1.8066\n",
            "Epoch 40/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 10.4767 - mean_absolute_error: 1.7736\n",
            "Epoch 41/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 9.9784 - mean_absolute_error: 1.7624\n",
            "Epoch 42/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 10.0629 - mean_absolute_error: 1.7595\n",
            "Epoch 43/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 10.0902 - mean_absolute_error: 1.7464\n",
            "Epoch 44/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 10.0990 - mean_absolute_error: 1.7609\n",
            "Epoch 45/150\n",
            "10381/10381 [==============================] - 2s 145us/step - loss: 9.9400 - mean_absolute_error: 1.7486\n",
            "Epoch 46/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 9.9830 - mean_absolute_error: 1.7581\n",
            "Epoch 47/150\n",
            "10381/10381 [==============================] - 2s 145us/step - loss: 9.7764 - mean_absolute_error: 1.7329\n",
            "Epoch 48/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 9.6208 - mean_absolute_error: 1.7155\n",
            "Epoch 49/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 9.7689 - mean_absolute_error: 1.7345\n",
            "Epoch 50/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 9.5857 - mean_absolute_error: 1.7147\n",
            "Epoch 51/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 9.1559 - mean_absolute_error: 1.6793\n",
            "Epoch 52/150\n",
            "10381/10381 [==============================] - 2s 166us/step - loss: 9.1213 - mean_absolute_error: 1.6894\n",
            "Epoch 53/150\n",
            "10381/10381 [==============================] - 2s 165us/step - loss: 9.0668 - mean_absolute_error: 1.6862\n",
            "Epoch 54/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 9.3799 - mean_absolute_error: 1.6986\n",
            "Epoch 55/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 9.1219 - mean_absolute_error: 1.6772\n",
            "Epoch 56/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 9.3446 - mean_absolute_error: 1.6840\n",
            "Epoch 57/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 8.9630 - mean_absolute_error: 1.6706\n",
            "Epoch 58/150\n",
            "10381/10381 [==============================] - 2s 145us/step - loss: 9.1859 - mean_absolute_error: 1.6812\n",
            "Epoch 59/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 9.4030 - mean_absolute_error: 1.6782\n",
            "Epoch 60/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.9243 - mean_absolute_error: 1.6588\n",
            "Epoch 61/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.8150 - mean_absolute_error: 1.6442\n",
            "Epoch 62/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.5154 - mean_absolute_error: 1.6391\n",
            "Epoch 63/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 9.0169 - mean_absolute_error: 1.6504\n",
            "Epoch 64/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 8.7961 - mean_absolute_error: 1.6545\n",
            "Epoch 65/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 8.6535 - mean_absolute_error: 1.6380\n",
            "Epoch 66/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 8.6726 - mean_absolute_error: 1.6361\n",
            "Epoch 67/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 8.3984 - mean_absolute_error: 1.6223\n",
            "Epoch 68/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 8.4800 - mean_absolute_error: 1.6425\n",
            "Epoch 69/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 8.5960 - mean_absolute_error: 1.6321\n",
            "Epoch 70/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 8.2973 - mean_absolute_error: 1.6126\n",
            "Epoch 71/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.5817 - mean_absolute_error: 1.6313\n",
            "Epoch 72/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.5946 - mean_absolute_error: 1.6214\n",
            "Epoch 73/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.4985 - mean_absolute_error: 1.6007\n",
            "Epoch 74/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 8.3296 - mean_absolute_error: 1.6012\n",
            "Epoch 75/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 8.5966 - mean_absolute_error: 1.6155\n",
            "Epoch 76/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 7.8920 - mean_absolute_error: 1.5668\n",
            "Epoch 77/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.1506 - mean_absolute_error: 1.5926\n",
            "Epoch 78/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 8.2171 - mean_absolute_error: 1.5833\n",
            "Epoch 79/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 8.0532 - mean_absolute_error: 1.5878\n",
            "Epoch 80/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.1612 - mean_absolute_error: 1.5871\n",
            "Epoch 81/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 7.9796 - mean_absolute_error: 1.5686\n",
            "Epoch 82/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 8.1108 - mean_absolute_error: 1.5833\n",
            "Epoch 83/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 8.1354 - mean_absolute_error: 1.5881\n",
            "Epoch 84/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.8808 - mean_absolute_error: 1.5640\n",
            "Epoch 85/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.8227 - mean_absolute_error: 1.5600\n",
            "Epoch 86/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 8.0103 - mean_absolute_error: 1.5592\n",
            "Epoch 87/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 7.8214 - mean_absolute_error: 1.5652\n",
            "Epoch 88/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 8.2103 - mean_absolute_error: 1.5682\n",
            "Epoch 89/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.8168 - mean_absolute_error: 1.5517\n",
            "Epoch 90/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.6511 - mean_absolute_error: 1.5450\n",
            "Epoch 91/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.6770 - mean_absolute_error: 1.5457\n",
            "Epoch 92/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 7.9000 - mean_absolute_error: 1.5589\n",
            "Epoch 93/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.5057 - mean_absolute_error: 1.5279\n",
            "Epoch 94/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 7.7213 - mean_absolute_error: 1.5354\n",
            "Epoch 95/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.4879 - mean_absolute_error: 1.5250\n",
            "Epoch 96/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 8.0590 - mean_absolute_error: 1.5732\n",
            "Epoch 97/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.6195 - mean_absolute_error: 1.5528\n",
            "Epoch 98/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 7.5583 - mean_absolute_error: 1.5261\n",
            "Epoch 99/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.8313 - mean_absolute_error: 1.5390\n",
            "Epoch 100/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.5483 - mean_absolute_error: 1.5208\n",
            "Epoch 101/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 7.6875 - mean_absolute_error: 1.5310\n",
            "Epoch 102/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 7.3814 - mean_absolute_error: 1.5196\n",
            "Epoch 103/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.2604 - mean_absolute_error: 1.4992\n",
            "Epoch 104/150\n",
            "10381/10381 [==============================] - 1s 144us/step - loss: 7.3216 - mean_absolute_error: 1.5265\n",
            "Epoch 105/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.4807 - mean_absolute_error: 1.5243\n",
            "Epoch 106/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.5278 - mean_absolute_error: 1.5130\n",
            "Epoch 107/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 7.7901 - mean_absolute_error: 1.5525\n",
            "Epoch 108/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 7.5572 - mean_absolute_error: 1.5240\n",
            "Epoch 109/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 7.1851 - mean_absolute_error: 1.5039\n",
            "Epoch 110/150\n",
            "10381/10381 [==============================] - 2s 145us/step - loss: 6.9686 - mean_absolute_error: 1.4766\n",
            "Epoch 111/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.4124 - mean_absolute_error: 1.5234\n",
            "Epoch 112/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.0148 - mean_absolute_error: 1.4891\n",
            "Epoch 113/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.9643 - mean_absolute_error: 1.4881\n",
            "Epoch 114/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.9543 - mean_absolute_error: 1.4796\n",
            "Epoch 115/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.2111 - mean_absolute_error: 1.5010\n",
            "Epoch 116/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 7.1376 - mean_absolute_error: 1.4871\n",
            "Epoch 117/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.9163 - mean_absolute_error: 1.4767\n",
            "Epoch 118/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 7.0974 - mean_absolute_error: 1.4798\n",
            "Epoch 119/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 7.1374 - mean_absolute_error: 1.4911\n",
            "Epoch 120/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 6.8637 - mean_absolute_error: 1.4749\n",
            "Epoch 121/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 7.0166 - mean_absolute_error: 1.4766\n",
            "Epoch 122/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 6.9364 - mean_absolute_error: 1.4638\n",
            "Epoch 123/150\n",
            "10381/10381 [==============================] - 2s 145us/step - loss: 6.9499 - mean_absolute_error: 1.4740\n",
            "Epoch 124/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 7.0698 - mean_absolute_error: 1.4843\n",
            "Epoch 125/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 6.8879 - mean_absolute_error: 1.4703\n",
            "Epoch 126/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 6.8145 - mean_absolute_error: 1.4699\n",
            "Epoch 127/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 6.9402 - mean_absolute_error: 1.4747\n",
            "Epoch 128/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.9580 - mean_absolute_error: 1.4707\n",
            "Epoch 129/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.7852 - mean_absolute_error: 1.4617\n",
            "Epoch 130/150\n",
            "10381/10381 [==============================] - 1s 143us/step - loss: 6.6697 - mean_absolute_error: 1.4486\n",
            "Epoch 131/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 6.7088 - mean_absolute_error: 1.4545\n",
            "Epoch 132/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 6.6790 - mean_absolute_error: 1.4522\n",
            "Epoch 133/150\n",
            "10381/10381 [==============================] - 2s 149us/step - loss: 6.7320 - mean_absolute_error: 1.4532\n",
            "Epoch 134/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 6.6353 - mean_absolute_error: 1.4447\n",
            "Epoch 135/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.6554 - mean_absolute_error: 1.4397\n",
            "Epoch 136/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 6.6257 - mean_absolute_error: 1.4375\n",
            "Epoch 137/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.6396 - mean_absolute_error: 1.4455\n",
            "Epoch 138/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 6.8515 - mean_absolute_error: 1.4540\n",
            "Epoch 139/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 6.5617 - mean_absolute_error: 1.4353\n",
            "Epoch 140/150\n",
            "10381/10381 [==============================] - 2s 146us/step - loss: 6.4358 - mean_absolute_error: 1.4273\n",
            "Epoch 141/150\n",
            "10381/10381 [==============================] - 2s 147us/step - loss: 6.6116 - mean_absolute_error: 1.4427\n",
            "Epoch 142/150\n",
            "10381/10381 [==============================] - 2s 165us/step - loss: 6.7642 - mean_absolute_error: 1.4527\n",
            "Epoch 143/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 6.6179 - mean_absolute_error: 1.4475\n",
            "Epoch 144/150\n",
            "10381/10381 [==============================] - 2s 168us/step - loss: 6.6150 - mean_absolute_error: 1.4426\n",
            "Epoch 145/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 6.2587 - mean_absolute_error: 1.4131\n",
            "Epoch 146/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.3204 - mean_absolute_error: 1.4176\n",
            "Epoch 147/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.2412 - mean_absolute_error: 1.4195\n",
            "Epoch 148/150\n",
            "10381/10381 [==============================] - 2s 151us/step - loss: 6.5233 - mean_absolute_error: 1.4301\n",
            "Epoch 149/150\n",
            "10381/10381 [==============================] - 2s 148us/step - loss: 6.2790 - mean_absolute_error: 1.4212\n",
            "Epoch 150/150\n",
            "10381/10381 [==============================] - 2s 150us/step - loss: 6.5926 - mean_absolute_error: 1.4387\n",
            "Kappa Score: 0.948135982939872\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_15 (Bidirectio (None, 1, 100)            40400     \n",
            "_________________________________________________________________\n",
            "lstm_31 (LSTM)               (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 82,705\n",
            "Trainable params: 82,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "10381/10381 [==============================] - 10s 992us/step - loss: 70.8935 - mean_absolute_error: 5.0434\n",
            "Epoch 2/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 44.4422 - mean_absolute_error: 3.8267\n",
            "Epoch 3/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 35.1856 - mean_absolute_error: 3.5134\n",
            "Epoch 4/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 31.2110 - mean_absolute_error: 3.3433\n",
            "Epoch 5/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 28.0881 - mean_absolute_error: 3.1753\n",
            "Epoch 6/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 26.3342 - mean_absolute_error: 3.0251\n",
            "Epoch 7/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 24.0228 - mean_absolute_error: 2.8623\n",
            "Epoch 8/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 22.3103 - mean_absolute_error: 2.7467\n",
            "Epoch 9/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 21.0921 - mean_absolute_error: 2.6027\n",
            "Epoch 10/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 19.5476 - mean_absolute_error: 2.5145\n",
            "Epoch 11/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 18.0445 - mean_absolute_error: 2.4007\n",
            "Epoch 12/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 17.0881 - mean_absolute_error: 2.3403\n",
            "Epoch 13/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 16.6872 - mean_absolute_error: 2.2958\n",
            "Epoch 14/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 15.5638 - mean_absolute_error: 2.2543\n",
            "Epoch 15/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 15.6847 - mean_absolute_error: 2.2072\n",
            "Epoch 16/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 14.9093 - mean_absolute_error: 2.1574\n",
            "Epoch 17/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 14.7359 - mean_absolute_error: 2.1599\n",
            "Epoch 18/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 14.1918 - mean_absolute_error: 2.0984\n",
            "Epoch 19/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 13.9566 - mean_absolute_error: 2.1018\n",
            "Epoch 20/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 13.3625 - mean_absolute_error: 2.0671\n",
            "Epoch 21/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 13.0872 - mean_absolute_error: 2.0339\n",
            "Epoch 22/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 13.0905 - mean_absolute_error: 2.0084\n",
            "Epoch 23/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 12.6289 - mean_absolute_error: 1.9866\n",
            "Epoch 24/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 12.6436 - mean_absolute_error: 1.9735\n",
            "Epoch 25/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 12.3337 - mean_absolute_error: 1.9451\n",
            "Epoch 26/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 12.0569 - mean_absolute_error: 1.9291\n",
            "Epoch 27/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 12.0834 - mean_absolute_error: 1.9253\n",
            "Epoch 28/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 11.6530 - mean_absolute_error: 1.8890\n",
            "Epoch 29/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 11.4494 - mean_absolute_error: 1.8699\n",
            "Epoch 30/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 11.3351 - mean_absolute_error: 1.8651\n",
            "Epoch 31/150\n",
            "10381/10381 [==============================] - 2s 165us/step - loss: 11.1594 - mean_absolute_error: 1.8584\n",
            "Epoch 32/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 11.4213 - mean_absolute_error: 1.8668\n",
            "Epoch 33/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 11.1903 - mean_absolute_error: 1.8357\n",
            "Epoch 34/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 11.0612 - mean_absolute_error: 1.8098\n",
            "Epoch 35/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 10.7911 - mean_absolute_error: 1.8131\n",
            "Epoch 36/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 10.4011 - mean_absolute_error: 1.7779\n",
            "Epoch 37/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 10.5841 - mean_absolute_error: 1.7951\n",
            "Epoch 38/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 10.6657 - mean_absolute_error: 1.7976\n",
            "Epoch 39/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 10.3481 - mean_absolute_error: 1.7648\n",
            "Epoch 40/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 10.4491 - mean_absolute_error: 1.7741\n",
            "Epoch 41/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 10.2909 - mean_absolute_error: 1.7551\n",
            "Epoch 42/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 10.3425 - mean_absolute_error: 1.7540\n",
            "Epoch 43/150\n",
            "10381/10381 [==============================] - 2s 165us/step - loss: 9.7407 - mean_absolute_error: 1.7248\n",
            "Epoch 44/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 10.1472 - mean_absolute_error: 1.7445\n",
            "Epoch 45/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 9.6605 - mean_absolute_error: 1.7057\n",
            "Epoch 46/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 9.5803 - mean_absolute_error: 1.7061\n",
            "Epoch 47/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 9.6027 - mean_absolute_error: 1.7097\n",
            "Epoch 48/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 9.8534 - mean_absolute_error: 1.7095\n",
            "Epoch 49/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 9.1915 - mean_absolute_error: 1.6764\n",
            "Epoch 50/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 9.6620 - mean_absolute_error: 1.7109\n",
            "Epoch 51/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 9.3742 - mean_absolute_error: 1.6935\n",
            "Epoch 52/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 9.1279 - mean_absolute_error: 1.6779\n",
            "Epoch 53/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 9.2045 - mean_absolute_error: 1.6796\n",
            "Epoch 54/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 9.1661 - mean_absolute_error: 1.6845\n",
            "Epoch 55/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 9.2293 - mean_absolute_error: 1.6762\n",
            "Epoch 56/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 9.0049 - mean_absolute_error: 1.6554\n",
            "Epoch 57/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 8.9288 - mean_absolute_error: 1.6486\n",
            "Epoch 58/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 9.1069 - mean_absolute_error: 1.6632\n",
            "Epoch 59/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 9.1208 - mean_absolute_error: 1.6671\n",
            "Epoch 60/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 8.9852 - mean_absolute_error: 1.6512\n",
            "Epoch 61/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 8.7850 - mean_absolute_error: 1.6326\n",
            "Epoch 62/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 8.9676 - mean_absolute_error: 1.6586\n",
            "Epoch 63/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 8.7565 - mean_absolute_error: 1.6226\n",
            "Epoch 64/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 8.5432 - mean_absolute_error: 1.6164\n",
            "Epoch 65/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 8.5043 - mean_absolute_error: 1.6194\n",
            "Epoch 66/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 8.8026 - mean_absolute_error: 1.6367\n",
            "Epoch 67/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 8.1834 - mean_absolute_error: 1.5930\n",
            "Epoch 68/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 8.6291 - mean_absolute_error: 1.6209\n",
            "Epoch 69/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 8.2029 - mean_absolute_error: 1.5838\n",
            "Epoch 70/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 8.3186 - mean_absolute_error: 1.6092\n",
            "Epoch 71/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 8.0107 - mean_absolute_error: 1.5802\n",
            "Epoch 72/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 8.2782 - mean_absolute_error: 1.5988\n",
            "Epoch 73/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 8.1635 - mean_absolute_error: 1.5873\n",
            "Epoch 74/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 8.2824 - mean_absolute_error: 1.6018\n",
            "Epoch 75/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 8.2548 - mean_absolute_error: 1.5857\n",
            "Epoch 76/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 7.9272 - mean_absolute_error: 1.5736\n",
            "Epoch 77/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 8.2597 - mean_absolute_error: 1.5976\n",
            "Epoch 78/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 7.8984 - mean_absolute_error: 1.5616\n",
            "Epoch 79/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 8.2739 - mean_absolute_error: 1.5912\n",
            "Epoch 80/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 8.0220 - mean_absolute_error: 1.5526\n",
            "Epoch 81/150\n",
            "10381/10381 [==============================] - 2s 168us/step - loss: 7.8459 - mean_absolute_error: 1.5605\n",
            "Epoch 82/150\n",
            "10381/10381 [==============================] - 2s 173us/step - loss: 7.9123 - mean_absolute_error: 1.5567\n",
            "Epoch 83/150\n",
            "10381/10381 [==============================] - 2s 173us/step - loss: 7.6746 - mean_absolute_error: 1.5576\n",
            "Epoch 84/150\n",
            "10381/10381 [==============================] - 2s 173us/step - loss: 7.8087 - mean_absolute_error: 1.5646\n",
            "Epoch 85/150\n",
            "10381/10381 [==============================] - 2s 174us/step - loss: 7.4209 - mean_absolute_error: 1.5323\n",
            "Epoch 86/150\n",
            "10381/10381 [==============================] - 2s 172us/step - loss: 7.5999 - mean_absolute_error: 1.5485\n",
            "Epoch 87/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 7.7028 - mean_absolute_error: 1.5444\n",
            "Epoch 88/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 7.6565 - mean_absolute_error: 1.5446\n",
            "Epoch 89/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 7.4691 - mean_absolute_error: 1.5323\n",
            "Epoch 90/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 7.6606 - mean_absolute_error: 1.5332\n",
            "Epoch 91/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 7.5218 - mean_absolute_error: 1.5380\n",
            "Epoch 92/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 7.3364 - mean_absolute_error: 1.5291\n",
            "Epoch 93/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 7.4457 - mean_absolute_error: 1.5290\n",
            "Epoch 94/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 7.3889 - mean_absolute_error: 1.5218\n",
            "Epoch 95/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 7.8062 - mean_absolute_error: 1.5475\n",
            "Epoch 96/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 7.4092 - mean_absolute_error: 1.5085\n",
            "Epoch 97/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 7.1329 - mean_absolute_error: 1.4978\n",
            "Epoch 98/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 7.1964 - mean_absolute_error: 1.5090\n",
            "Epoch 99/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 7.4776 - mean_absolute_error: 1.5207\n",
            "Epoch 100/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 7.1372 - mean_absolute_error: 1.5046\n",
            "Epoch 101/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 7.2913 - mean_absolute_error: 1.5025\n",
            "Epoch 102/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 6.9975 - mean_absolute_error: 1.4886\n",
            "Epoch 103/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 7.3863 - mean_absolute_error: 1.5129\n",
            "Epoch 104/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 7.1860 - mean_absolute_error: 1.5069\n",
            "Epoch 105/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 7.2399 - mean_absolute_error: 1.5019\n",
            "Epoch 106/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 7.2395 - mean_absolute_error: 1.5019\n",
            "Epoch 107/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 7.4221 - mean_absolute_error: 1.5163\n",
            "Epoch 108/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 7.1182 - mean_absolute_error: 1.4953\n",
            "Epoch 109/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.9293 - mean_absolute_error: 1.4808\n",
            "Epoch 110/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 6.8066 - mean_absolute_error: 1.4763\n",
            "Epoch 111/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 7.0106 - mean_absolute_error: 1.4830\n",
            "Epoch 112/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 6.8610 - mean_absolute_error: 1.4719\n",
            "Epoch 113/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 6.8569 - mean_absolute_error: 1.4824\n",
            "Epoch 114/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 6.9227 - mean_absolute_error: 1.4802\n",
            "Epoch 115/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 6.8249 - mean_absolute_error: 1.4641\n",
            "Epoch 116/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 6.7654 - mean_absolute_error: 1.4674\n",
            "Epoch 117/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 7.0341 - mean_absolute_error: 1.4792\n",
            "Epoch 118/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.6132 - mean_absolute_error: 1.4539\n",
            "Epoch 119/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 6.6063 - mean_absolute_error: 1.4511\n",
            "Epoch 120/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.8405 - mean_absolute_error: 1.4608\n",
            "Epoch 121/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.4637 - mean_absolute_error: 1.4328\n",
            "Epoch 122/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 6.9123 - mean_absolute_error: 1.4706\n",
            "Epoch 123/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.7743 - mean_absolute_error: 1.4529\n",
            "Epoch 124/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 6.4609 - mean_absolute_error: 1.4406\n",
            "Epoch 125/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.7766 - mean_absolute_error: 1.4607\n",
            "Epoch 126/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 6.7128 - mean_absolute_error: 1.4485\n",
            "Epoch 127/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 6.4090 - mean_absolute_error: 1.4444\n",
            "Epoch 128/150\n",
            "10381/10381 [==============================] - 2s 154us/step - loss: 6.4156 - mean_absolute_error: 1.4270\n",
            "Epoch 129/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.3369 - mean_absolute_error: 1.4272\n",
            "Epoch 130/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.4181 - mean_absolute_error: 1.4380\n",
            "Epoch 131/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.5883 - mean_absolute_error: 1.4415\n",
            "Epoch 132/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.4901 - mean_absolute_error: 1.4371\n",
            "Epoch 133/150\n",
            "10381/10381 [==============================] - 2s 153us/step - loss: 6.4459 - mean_absolute_error: 1.4321\n",
            "Epoch 134/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.4229 - mean_absolute_error: 1.4323\n",
            "Epoch 135/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 6.3174 - mean_absolute_error: 1.4398\n",
            "Epoch 136/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 6.3693 - mean_absolute_error: 1.4278\n",
            "Epoch 137/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.3943 - mean_absolute_error: 1.4381\n",
            "Epoch 138/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 6.4877 - mean_absolute_error: 1.4319\n",
            "Epoch 139/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 6.1789 - mean_absolute_error: 1.4142\n",
            "Epoch 140/150\n",
            "10381/10381 [==============================] - 2s 152us/step - loss: 6.3495 - mean_absolute_error: 1.4218\n",
            "Epoch 141/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.3315 - mean_absolute_error: 1.4163\n",
            "Epoch 142/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.3351 - mean_absolute_error: 1.4282\n",
            "Epoch 143/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 6.2158 - mean_absolute_error: 1.4148\n",
            "Epoch 144/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.3552 - mean_absolute_error: 1.4245\n",
            "Epoch 145/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.5585 - mean_absolute_error: 1.4287\n",
            "Epoch 146/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 6.2361 - mean_absolute_error: 1.4089\n",
            "Epoch 147/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 6.1765 - mean_absolute_error: 1.3975\n",
            "Epoch 148/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 6.1954 - mean_absolute_error: 1.4160\n",
            "Epoch 149/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 6.2724 - mean_absolute_error: 1.4126\n",
            "Epoch 150/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.1948 - mean_absolute_error: 1.4137\n",
            "Kappa Score: 0.945667079061977\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_16 (Bidirectio (None, 1, 100)            40400     \n",
            "_________________________________________________________________\n",
            "lstm_33 (LSTM)               (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 82,705\n",
            "Trainable params: 82,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "10381/10381 [==============================] - 11s 1ms/step - loss: 73.1020 - mean_absolute_error: 5.0857\n",
            "Epoch 2/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 44.9050 - mean_absolute_error: 3.8655\n",
            "Epoch 3/150\n",
            "10381/10381 [==============================] - 2s 171us/step - loss: 35.1351 - mean_absolute_error: 3.5040\n",
            "Epoch 4/150\n",
            "10381/10381 [==============================] - 2s 175us/step - loss: 30.9590 - mean_absolute_error: 3.2874\n",
            "Epoch 5/150\n",
            "10381/10381 [==============================] - 2s 177us/step - loss: 28.0838 - mean_absolute_error: 3.1226\n",
            "Epoch 6/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 25.6460 - mean_absolute_error: 2.9271\n",
            "Epoch 7/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 23.5769 - mean_absolute_error: 2.7898\n",
            "Epoch 8/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 21.5323 - mean_absolute_error: 2.6603\n",
            "Epoch 9/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 19.8509 - mean_absolute_error: 2.5286\n",
            "Epoch 10/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 18.6092 - mean_absolute_error: 2.4400\n",
            "Epoch 11/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 17.3252 - mean_absolute_error: 2.3458\n",
            "Epoch 12/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 16.4955 - mean_absolute_error: 2.2834\n",
            "Epoch 13/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 15.7922 - mean_absolute_error: 2.2431\n",
            "Epoch 14/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 15.1100 - mean_absolute_error: 2.1918\n",
            "Epoch 15/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 14.9617 - mean_absolute_error: 2.1677\n",
            "Epoch 16/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 14.4878 - mean_absolute_error: 2.1256\n",
            "Epoch 17/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 14.1071 - mean_absolute_error: 2.1026\n",
            "Epoch 18/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 13.9041 - mean_absolute_error: 2.0678\n",
            "Epoch 19/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 13.3557 - mean_absolute_error: 2.0328\n",
            "Epoch 20/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 13.2743 - mean_absolute_error: 2.0152\n",
            "Epoch 21/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 12.6313 - mean_absolute_error: 1.9814\n",
            "Epoch 22/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 12.7889 - mean_absolute_error: 1.9843\n",
            "Epoch 23/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 12.2330 - mean_absolute_error: 1.9492\n",
            "Epoch 24/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 12.0033 - mean_absolute_error: 1.9139\n",
            "Epoch 25/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 11.8048 - mean_absolute_error: 1.9003\n",
            "Epoch 26/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 11.6944 - mean_absolute_error: 1.9034\n",
            "Epoch 27/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 11.5115 - mean_absolute_error: 1.8713\n",
            "Epoch 28/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 11.2459 - mean_absolute_error: 1.8605\n",
            "Epoch 29/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 11.3275 - mean_absolute_error: 1.8512\n",
            "Epoch 30/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 11.1015 - mean_absolute_error: 1.8285\n",
            "Epoch 31/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 11.1548 - mean_absolute_error: 1.8373\n",
            "Epoch 32/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 10.8249 - mean_absolute_error: 1.8053\n",
            "Epoch 33/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 10.7939 - mean_absolute_error: 1.8122\n",
            "Epoch 34/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 10.8062 - mean_absolute_error: 1.8010\n",
            "Epoch 35/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 10.5608 - mean_absolute_error: 1.7857\n",
            "Epoch 36/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 10.7413 - mean_absolute_error: 1.7861\n",
            "Epoch 37/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 10.3042 - mean_absolute_error: 1.7597\n",
            "Epoch 38/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 9.9674 - mean_absolute_error: 1.7449\n",
            "Epoch 39/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 10.1439 - mean_absolute_error: 1.7614\n",
            "Epoch 40/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 9.8465 - mean_absolute_error: 1.7240\n",
            "Epoch 41/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 10.0603 - mean_absolute_error: 1.7396\n",
            "Epoch 42/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 9.9966 - mean_absolute_error: 1.7313\n",
            "Epoch 43/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 9.7693 - mean_absolute_error: 1.7199\n",
            "Epoch 44/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 9.4833 - mean_absolute_error: 1.7005\n",
            "Epoch 45/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 9.6854 - mean_absolute_error: 1.6844\n",
            "Epoch 46/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 9.5290 - mean_absolute_error: 1.6911\n",
            "Epoch 47/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 9.7024 - mean_absolute_error: 1.7070\n",
            "Epoch 48/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 9.3685 - mean_absolute_error: 1.6868\n",
            "Epoch 49/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 9.2667 - mean_absolute_error: 1.6661\n",
            "Epoch 50/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 9.3790 - mean_absolute_error: 1.6906\n",
            "Epoch 51/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 8.8993 - mean_absolute_error: 1.6670\n",
            "Epoch 52/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 9.4100 - mean_absolute_error: 1.6795\n",
            "Epoch 53/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 9.2559 - mean_absolute_error: 1.6664\n",
            "Epoch 54/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 8.8307 - mean_absolute_error: 1.6386\n",
            "Epoch 55/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 8.9824 - mean_absolute_error: 1.6490\n",
            "Epoch 56/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 9.0232 - mean_absolute_error: 1.6489\n",
            "Epoch 57/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 9.0811 - mean_absolute_error: 1.6551\n",
            "Epoch 58/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 8.7949 - mean_absolute_error: 1.6445\n",
            "Epoch 59/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 8.5996 - mean_absolute_error: 1.6230\n",
            "Epoch 60/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 8.6604 - mean_absolute_error: 1.6269\n",
            "Epoch 61/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 8.5791 - mean_absolute_error: 1.6148\n",
            "Epoch 62/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 8.7010 - mean_absolute_error: 1.6237\n",
            "Epoch 63/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 8.2266 - mean_absolute_error: 1.5999\n",
            "Epoch 64/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 8.5158 - mean_absolute_error: 1.6142\n",
            "Epoch 65/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 8.7830 - mean_absolute_error: 1.6393\n",
            "Epoch 66/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 8.5884 - mean_absolute_error: 1.6205\n",
            "Epoch 67/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 8.4285 - mean_absolute_error: 1.5914\n",
            "Epoch 68/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 8.0595 - mean_absolute_error: 1.5850\n",
            "Epoch 69/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 8.3617 - mean_absolute_error: 1.6035\n",
            "Epoch 70/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 8.1983 - mean_absolute_error: 1.5927\n",
            "Epoch 71/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 8.6342 - mean_absolute_error: 1.6145\n",
            "Epoch 72/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 8.2177 - mean_absolute_error: 1.5935\n",
            "Epoch 73/150\n",
            "10381/10381 [==============================] - 2s 165us/step - loss: 8.2139 - mean_absolute_error: 1.5896\n",
            "Epoch 74/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 7.9647 - mean_absolute_error: 1.5741\n",
            "Epoch 75/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 8.1650 - mean_absolute_error: 1.5825\n",
            "Epoch 76/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 8.4918 - mean_absolute_error: 1.5965\n",
            "Epoch 77/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 7.9609 - mean_absolute_error: 1.5673\n",
            "Epoch 78/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 8.0785 - mean_absolute_error: 1.5711\n",
            "Epoch 79/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 7.7843 - mean_absolute_error: 1.5603\n",
            "Epoch 80/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 7.9880 - mean_absolute_error: 1.5664\n",
            "Epoch 81/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 7.9133 - mean_absolute_error: 1.5572\n",
            "Epoch 82/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 7.8629 - mean_absolute_error: 1.5578\n",
            "Epoch 83/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 7.8374 - mean_absolute_error: 1.5699\n",
            "Epoch 84/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 7.7722 - mean_absolute_error: 1.5390\n",
            "Epoch 85/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 7.8699 - mean_absolute_error: 1.5576\n",
            "Epoch 86/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 7.8783 - mean_absolute_error: 1.5459\n",
            "Epoch 87/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 7.5650 - mean_absolute_error: 1.5236\n",
            "Epoch 88/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 7.7765 - mean_absolute_error: 1.5447\n",
            "Epoch 89/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 7.6413 - mean_absolute_error: 1.5282\n",
            "Epoch 90/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 7.8513 - mean_absolute_error: 1.5428\n",
            "Epoch 91/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 7.8542 - mean_absolute_error: 1.5350\n",
            "Epoch 92/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 7.4904 - mean_absolute_error: 1.5289\n",
            "Epoch 93/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 7.5932 - mean_absolute_error: 1.5222\n",
            "Epoch 94/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 7.8898 - mean_absolute_error: 1.5641\n",
            "Epoch 95/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 7.3334 - mean_absolute_error: 1.5183\n",
            "Epoch 96/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 7.2518 - mean_absolute_error: 1.5110\n",
            "Epoch 97/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 7.1942 - mean_absolute_error: 1.5060\n",
            "Epoch 98/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 7.3947 - mean_absolute_error: 1.5152\n",
            "Epoch 99/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 7.6466 - mean_absolute_error: 1.5335\n",
            "Epoch 100/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 7.6091 - mean_absolute_error: 1.5327\n",
            "Epoch 101/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 7.2982 - mean_absolute_error: 1.5024\n",
            "Epoch 102/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 7.3914 - mean_absolute_error: 1.5154\n",
            "Epoch 103/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 7.2842 - mean_absolute_error: 1.5037\n",
            "Epoch 104/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 7.1706 - mean_absolute_error: 1.5045\n",
            "Epoch 105/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 7.5690 - mean_absolute_error: 1.5245\n",
            "Epoch 106/150\n",
            "10381/10381 [==============================] - 2s 164us/step - loss: 7.0147 - mean_absolute_error: 1.4914\n",
            "Epoch 107/150\n",
            "10381/10381 [==============================] - 2s 169us/step - loss: 7.0972 - mean_absolute_error: 1.4932\n",
            "Epoch 108/150\n",
            "10381/10381 [==============================] - 2s 168us/step - loss: 7.2305 - mean_absolute_error: 1.5087\n",
            "Epoch 109/150\n",
            "10381/10381 [==============================] - 2s 169us/step - loss: 7.0646 - mean_absolute_error: 1.4951\n",
            "Epoch 110/150\n",
            "10381/10381 [==============================] - 2s 171us/step - loss: 7.1264 - mean_absolute_error: 1.4977\n",
            "Epoch 111/150\n",
            "10381/10381 [==============================] - 2s 171us/step - loss: 7.2493 - mean_absolute_error: 1.4999\n",
            "Epoch 112/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 7.1151 - mean_absolute_error: 1.4848\n",
            "Epoch 113/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 6.8797 - mean_absolute_error: 1.4826\n",
            "Epoch 114/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 7.0189 - mean_absolute_error: 1.4782\n",
            "Epoch 115/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.6561 - mean_absolute_error: 1.4622\n",
            "Epoch 116/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.9529 - mean_absolute_error: 1.4735\n",
            "Epoch 117/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 7.1359 - mean_absolute_error: 1.4784\n",
            "Epoch 118/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 6.8730 - mean_absolute_error: 1.4742\n",
            "Epoch 119/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 6.7320 - mean_absolute_error: 1.4534\n",
            "Epoch 120/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.7812 - mean_absolute_error: 1.4594\n",
            "Epoch 121/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.5998 - mean_absolute_error: 1.4405\n",
            "Epoch 122/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.8759 - mean_absolute_error: 1.4652\n",
            "Epoch 123/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.6639 - mean_absolute_error: 1.4647\n",
            "Epoch 124/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 6.7489 - mean_absolute_error: 1.4644\n",
            "Epoch 125/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.8811 - mean_absolute_error: 1.4698\n",
            "Epoch 126/150\n",
            "10381/10381 [==============================] - 2s 155us/step - loss: 6.6449 - mean_absolute_error: 1.4475\n",
            "Epoch 127/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 6.5430 - mean_absolute_error: 1.4499\n",
            "Epoch 128/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.6767 - mean_absolute_error: 1.4487\n",
            "Epoch 129/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.6379 - mean_absolute_error: 1.4551\n",
            "Epoch 130/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 6.4829 - mean_absolute_error: 1.4397\n",
            "Epoch 131/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.7400 - mean_absolute_error: 1.4547\n",
            "Epoch 132/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 6.7108 - mean_absolute_error: 1.4471\n",
            "Epoch 133/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 6.7221 - mean_absolute_error: 1.4542\n",
            "Epoch 134/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 6.8277 - mean_absolute_error: 1.4643\n",
            "Epoch 135/150\n",
            "10381/10381 [==============================] - 2s 157us/step - loss: 6.6070 - mean_absolute_error: 1.4573\n",
            "Epoch 136/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 6.4433 - mean_absolute_error: 1.4349\n",
            "Epoch 137/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 6.3622 - mean_absolute_error: 1.4214\n",
            "Epoch 138/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 6.6074 - mean_absolute_error: 1.4512\n",
            "Epoch 139/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 6.6414 - mean_absolute_error: 1.4491\n",
            "Epoch 140/150\n",
            "10381/10381 [==============================] - 2s 156us/step - loss: 6.7637 - mean_absolute_error: 1.4569\n",
            "Epoch 141/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.4356 - mean_absolute_error: 1.4228\n",
            "Epoch 142/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 6.2457 - mean_absolute_error: 1.4261\n",
            "Epoch 143/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.4889 - mean_absolute_error: 1.4349\n",
            "Epoch 144/150\n",
            "10381/10381 [==============================] - 2s 161us/step - loss: 6.2781 - mean_absolute_error: 1.4168\n",
            "Epoch 145/150\n",
            "10381/10381 [==============================] - 2s 163us/step - loss: 6.5011 - mean_absolute_error: 1.4393\n",
            "Epoch 146/150\n",
            "10381/10381 [==============================] - 2s 159us/step - loss: 6.2260 - mean_absolute_error: 1.4146\n",
            "Epoch 147/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 6.1618 - mean_absolute_error: 1.4114\n",
            "Epoch 148/150\n",
            "10381/10381 [==============================] - 2s 162us/step - loss: 6.3410 - mean_absolute_error: 1.4141\n",
            "Epoch 149/150\n",
            "10381/10381 [==============================] - 2s 160us/step - loss: 6.2827 - mean_absolute_error: 1.4210\n",
            "Epoch 150/150\n",
            "10381/10381 [==============================] - 2s 158us/step - loss: 6.2171 - mean_absolute_error: 1.4061\n",
            "Kappa Score: 0.9451562857064553\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}